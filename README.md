# Набор данных о риске и степени тяжести астмы


- [Описание набора данных](#описание-набора-данных)
- [Структура проекта](#Структура-проекта)
- [ETL-пакет для обработки медицинских данных](#etl-пакет-для-обработки-медицинских-данных)
  - [ Запуск всего конвейера](#-запуск-всего-конвейера)
  - [ Запуск отдельных этапов](#-запуск-отдельных-этапов)
  - [ Функциональность ETL](#-функциональность-etl)
    - [ Extract](#-extract)
    - [ Transform](#-transform)
    - [ Load](#-load)
- [ Зависимости проекта](#️-зависимости-проекта)




---

### [Описание набора данных](https://drive.google.com/file/d/1e_B0JuGIwMeVWKbchUdzw8xcAkh0hPbX/view?usp=drive_link)

Этот синтетический набор данных моделирует медицинские записи людей с различными степенями тяжести астмы.  
Он создан для поддержки задач предсказательного моделирования, классификации и исследовательского анализа в области здравоохранения.

Набор данных содержит информацию на уровне пациента, включая демографические характеристики, образ жизни, воздействие факторов окружающей среды и медицинские показатели, которые влияют на риск и степень тяжести астмы.

Возможные сценарии использования:

- [Прогнозирование степени тяжести астмы]  
- [Оценка риска для здоровья]  
- [Анализ влияния факторов, таких как загрязнение, индекс массы тела (BMI) или курение]  
- [Образовательные задачи машинного обучения]

Так как данные полностью синтетические, они безопасны для публичного использования и не содержат персональной или конфиденциальной информации.


---


##  Структура проекта

```
├───
│   pyproject.toml
│   README.md
│   requirements.txt
│   ├───api_example
│   │   api_reader.py
│   │   README.md
│   │   requirements.txt
│   ├───etl
│   │   extract.py
│   │   load.py
│   │   main.py
│   │   transform.py
│   │   __init__.py
│   ├───notebooks
│   │   EDA.ipynb
```        
---
## Установка 
   - Создание и активация окружения
     ```
     conda create -n my_env python=3.13 pip
     conda activate my_env
     ```
  - Установка зависимостей 
     ```
     pip install -r requirements.txt
     ```
---

##  ETL-пакет для обработки медицинских данных

Данный проект реализует полноценный **ETL-конвейер** для загрузки, очистки и выгрузки данных о пациентах.  
Все этапы объединены в пакет `etl`, состоящий из трёх модулей:

- **`extract.py`** — загрузка исходных данных из Google Drive по `file_id`  
- **`transform.py`** — очистка, нормализация и валидация данных, сохранение в `.csv` и `.parquet`  
- **`load.py`** — загрузка очищенных данных (макс. 100 строк) в базу данных PostgreSQL  



###  Запуск всего конвейера


```
python etl/main.py (file-id)
```
Параметр file-id — это ID файла на Google Drive, например часть ссылки: https: //drive.google.com/file/d/<file_id>/view


###  Запуск отдельных этапов
```
 #Только извлечение данных
   python etl/extract.py 

 # Только очистка и преобразование
   python etl/transform.py  

 # Только загрузка в базу данных
   python etl/load.py
```
###  Функциональность ETL

####  Extract  
- Загрузка CSV-файла из Google Drive по `file_id`  
- Сохранение данных в `data/raw/raw_data.csv`  

####  Transform  
- Очистка текстовых и числовых столбцов  
- Проверка корректности возраста и BMI  
- Сохранение результатов в `data/processed/clean_data.csv` и `clean_data.parquet`  
- Валидация выходных параметров (размер, типы данных, отсутствие дубликатов)  

####  Load  
- Чтение данных из `clean_data.parquet`  
- Ввод пользователем параметров подключения к PostgreSQL  
- Создание таблицы (если отсутствует)  
- Загрузка максимум **100 строк**  
- Проверка количества записей после вставки  

  ---
##  Зависимости проекта

Основные библиотеки, используемые в проекте:

- `pandas` – обработка и анализ данных, удобная работа с таблицами и структурированными данными  
- `numpy` – математические и численные вычисления, поддержка массивов и статистических операций  
- `requests` – взаимодействие с внешними API, например для получения данных о погоде  
- `matplotlib` – базовые графики и визуализация данных  
- `seaborn` – статистическая визуализация, красивые диаграммы и тепловые карты  
- `psycopg2-binary` – подключение и работа с базой данных PostgreSQL  
- `pyarrow` – работа с форматом Parquet для эффективного хранения и чтения больших наборов данных  







